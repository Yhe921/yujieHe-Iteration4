{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import sys\n",
    "import math\n",
    "from scipy.stats import nbinom\n",
    "from torch.nn.utils import weight_norm\n",
    "\n",
    "# Define the NB class first, not mixture version\n",
    "class NBNorm(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(NBNorm,self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.n_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        \n",
    "        self.p_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        self.out_dim = c_out # output horizon\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1,3)\n",
    "        (B, _, N,_) = x.shape # B: batch_size; N: input nodes\n",
    "        n = self.n_conv(x).squeeze_(-1)\n",
    "        p = self.p_conv(x).squeeze_(-1)\n",
    "\n",
    "        # Reshape\n",
    "        n = n.view([B,self.out_dim,N])\n",
    "        p = p.view([B,self.out_dim,N])\n",
    "\n",
    "        # Ensure n is positive and p between 0 and 1\n",
    "        n = F.softplus(n) # Some parameters can be tuned here\n",
    "        p = F.sigmoid(p)\n",
    "        return n.permute([0,2,1]), p.permute([0,2,1])\n",
    "\n",
    "    def likelihood_loss(self,y,n,p,y_mask=None):\n",
    "        \"\"\"\n",
    "        y: true values\n",
    "        y_mask: whether missing mask is given\n",
    "        \"\"\"\n",
    "        nll = torch.lgamma(n) + torch.lgamma(y+1) - torch.lgamma(n+y) - n*torch.log(p) - y*torch.log(1-p)\n",
    "        if y_mask is not None:\n",
    "            nll = nll*y_mask\n",
    "        return torch.sum(nll)\n",
    "\n",
    "    def mean(self,n,p):\n",
    "        \"\"\"\n",
    "        :param cat: Input data of shape (batch_size, num_timesteps, in_nodes)\n",
    "        :return: Output data of shape (batch_size, 1, num_timesteps, in_nodes)\n",
    "        \"\"\" \n",
    "        pass\n",
    "\n",
    "# Define the Gaussian \n",
    "class GaussNorm(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(GaussNorm,self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.n_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        \n",
    "        self.p_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        self.out_dim = c_out # output horizon\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1,3)\n",
    "        (B, _, N,_) = x.shape # B: batch_size; N: input nodes\n",
    "        loc    = self.n_conv(x).squeeze_(-1) # The location (loc) keyword specifies the mean. The scale (scale) keyword specifies the standard deviation.\n",
    "        scale  = self.p_conv(x).squeeze_(-1)\n",
    "\n",
    "        # Reshape\n",
    "        loc   = loc.view([B,self.out_dim,N])\n",
    "        scale = scale.view([B,self.out_dim,N])\n",
    "\n",
    "        # Ensure n is positive and p between 0 and 1\n",
    "        loc = F.softplus(loc) # Some parameters can be tuned here, count data are always positive\n",
    "        scale = F.sigmoid(scale)\n",
    "        return loc.permute([0,2,1]), scale.permute([0,2,1])\n",
    "\n",
    "# Define the NB class first, not mixture version\n",
    "class NBNorm_ZeroInflated(nn.Module):\n",
    "    def __init__(self, c_in, c_out):\n",
    "        super(NBNorm_ZeroInflated,self).__init__()\n",
    "        self.c_in = c_in\n",
    "        self.c_out = c_out\n",
    "        self.n_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "        \n",
    "        self.p_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "\n",
    "        self.pi_conv = nn.Conv2d(in_channels=c_in,\n",
    "                                    out_channels=c_out,\n",
    "                                    kernel_size=(1,1),\n",
    "                                    bias=True)\n",
    "                                    \n",
    "        self.out_dim = c_out # output horizon\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0,2,1,3)\n",
    "        (B, _, N,_) = x.shape # B: batch_size; N: input nodes\n",
    "        n  = self.n_conv(x).squeeze_(-1)\n",
    "        p  = self.p_conv(x).squeeze_(-1)\n",
    "        pi = self.pi_conv(x).squeeze_(-1)\n",
    "\n",
    "        # Reshape\n",
    "        n = n.view([B,self.out_dim,N])\n",
    "        p = p.view([B,self.out_dim,N])\n",
    "        pi = pi.view([B,self.out_dim,N])\n",
    "\n",
    "        # Ensure n is positive and p between 0 and 1\n",
    "        n = F.softplus(n) # Some parameters can be tuned here\n",
    "        p = F.sigmoid(p)\n",
    "        pi = F.sigmoid(pi)\n",
    "        return n.permute([0,2,1]), p.permute([0,2,1]), pi.permute([0,2,1])\n",
    "\n",
    "class D_GCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a diffusion graph convolution to sampled location\n",
    "    \"\"\"       \n",
    "    def __init__(self, in_channels, out_channels, orders, activation = 'relu'): \n",
    "        \"\"\"\n",
    "        :param in_channels: Number of time step.\n",
    "        :param out_channels: Desired number of output features at each node in\n",
    "        each time step.\n",
    "        :param order: The diffusion steps.\n",
    "        \"\"\"\n",
    "        super(D_GCN, self).__init__()\n",
    "        self.orders = orders\n",
    "        self.activation = activation\n",
    "        self.num_matrices = 2 * self.orders + 1\n",
    "        self.Theta1 = nn.Parameter(torch.FloatTensor(in_channels * self.num_matrices,\n",
    "                                             out_channels))\n",
    "        self.bias = nn.Parameter(torch.FloatTensor(out_channels))\n",
    "        self.reset_parameters()\n",
    "        \n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.Theta1.shape[1])\n",
    "        self.Theta1.data.uniform_(-stdv, stdv)\n",
    "        stdv1 = 1. / math.sqrt(self.bias.shape[0])\n",
    "        self.bias.data.uniform_(-stdv1, stdv1)\n",
    "        \n",
    "    def _concat(self, x, x_):\n",
    "        x_ = x_.unsqueeze(0)\n",
    "        return torch.cat([x, x_], dim=0)\n",
    "        \n",
    "    def forward(self, X, A_q, A_h):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_nodes, num_timesteps)\n",
    "        :A_q: The forward random walk matrix (num_nodes, num_nodes)\n",
    "        :A_h: The backward random walk matrix (num_nodes, num_nodes)\n",
    "        :return: Output data of shape (batch_size, num_nodes, num_features)\n",
    "        \"\"\"\n",
    "        batch_size = X.shape[0] # batch_size\n",
    "        num_node = X.shape[1]\n",
    "        input_size = X.size(2)  # time_length\n",
    "        supports = []\n",
    "        supports.append(A_q)\n",
    "        supports.append(A_h)\n",
    "        \n",
    "        x0 = X.permute(1, 2, 0) #(num_nodes, num_times, batch_size)\n",
    "        x0 = torch.reshape(x0, shape=[num_node, input_size * batch_size])\n",
    "        x = torch.unsqueeze(x0, 0)\n",
    "        for support in supports:\n",
    "            x1 = torch.mm(support, x0)\n",
    "            x = self._concat(x, x1)\n",
    "            for k in range(2, self.orders + 1):\n",
    "                x2 = 2 * torch.mm(support, x1) - x0\n",
    "                x = self._concat(x, x2)\n",
    "                x1, x0 = x2, x1\n",
    "                \n",
    "        x = torch.reshape(x, shape=[self.num_matrices, num_node, input_size, batch_size])\n",
    "        x = x.permute(3, 1, 2, 0)  # (batch_size, num_nodes, input_size, order)\n",
    "        x = torch.reshape(x, shape=[batch_size, num_node, input_size * self.num_matrices])         \n",
    "        x = torch.matmul(x, self.Theta1)  # (batch_size * self._num_nodes, output_size)     \n",
    "        x += self.bias\n",
    "        if self.activation == 'relu':\n",
    "            x = F.relu(x)\n",
    "        elif self.activation == 'selu':\n",
    "            x = F.selu(x)   \n",
    "            \n",
    "        return x\n",
    "\n",
    "\n",
    "## Code of BTCN from Yuankai\n",
    "class B_TCN(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural network block that applies a bidirectional temporal convolution to each node of\n",
    "    a graph.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3,activation = 'relu',device='cuda'):\n",
    "        \"\"\"\n",
    "        :param in_channels: Number of nodes in the graph.\n",
    "        :param out_channels: Desired number of output features.\n",
    "        :param kernel_size: Size of the 1D temporal kernel.\n",
    "        \"\"\"\n",
    "        super(B_TCN, self).__init__()\n",
    "        # forward dirction temporal convolution\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.activation = activation\n",
    "        self.device = device\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv2 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv3 = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        \n",
    "        self.conv1b = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv2b = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        self.conv3b = nn.Conv2d(in_channels, out_channels, (1, kernel_size))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_timesteps, num_nodes)\n",
    "        :return: Output data of shape (batch_size, num_timesteps, num_features)\n",
    "        \"\"\"\n",
    "        batch_size = X.shape[0]\n",
    "        seq_len = X.shape[1]\n",
    "        Xf = X.unsqueeze(1)  # (batch_size, 1, num_timesteps, num_nodes)\n",
    "        \n",
    "        inv_idx = torch.arange(Xf.size(2)-1, -1, -1).long().to(device=self.device)#.to(device=self.device).to(device=self.device)\n",
    "        Xb = Xf.index_select(2, inv_idx) # inverse the direction of time\n",
    "        \n",
    "        Xf = Xf.permute(0, 3, 1, 2)\n",
    "        Xb = Xb.permute(0, 3, 1, 2) #(batch_size, num_nodes, 1, num_timesteps)\n",
    "        tempf = self.conv1(Xf) * torch.sigmoid(self.conv2(Xf)) #+\n",
    "        outf = tempf + self.conv3(Xf) \n",
    "        outf = outf.reshape([batch_size, seq_len - self.kernel_size + 1, self.out_channels])        \n",
    "        \n",
    "        tempb = self.conv1b(Xb) * torch.sigmoid(self.conv2b(Xb)) #+\n",
    "        outb = tempb + self.conv3b(Xb)\n",
    "        outb = outb.reshape([batch_size, seq_len - self.kernel_size + 1, self.out_channels])\n",
    "        \n",
    "        rec = torch.zeros([batch_size, self.kernel_size - 1, self.out_channels]).to(device=self.device)#.to(device=self.device)\n",
    "        outf = torch.cat((outf, rec), dim = 1)\n",
    "        outb = torch.cat((outb, rec), dim = 1) #(batch_size, num_timesteps, out_features)\n",
    "        \n",
    "        inv_idx = torch.arange(outb.size(1)-1, -1, -1).long().to(device=self.device)#.to(device=self.device)\n",
    "        outb = outb.index_select(1, inv_idx)\n",
    "        out = outf + outb\n",
    "        if self.activation == 'relu':\n",
    "            out = F.relu(outf) + F.relu(outb)\n",
    "        elif self.activation == 'sigmoid':\n",
    "            out = F.sigmoid(outf) + F.sigmoid(outb)       \n",
    "        return out\n",
    "\n",
    "\n",
    "class ST_NB(nn.Module):\n",
    "    \"\"\"\n",
    "  wx_t  + wx_s\n",
    "    |       |\n",
    "   TC4     SC4\n",
    "    |       |\n",
    "   TC3     SC3\n",
    "    |       |\n",
    "   z_t     z_s\n",
    "    |       |\n",
    "   TC2     SC2\n",
    "    |       |  \n",
    "   TC1     SC1\n",
    "    |       |\n",
    "   x_m     x_m\n",
    "    \"\"\"\n",
    "    def __init__(self, SC1, SC2, SC3, TC1, TC2, TC3, SNB,TNB): \n",
    "        super(ST_NB, self).__init__()\n",
    "        self.TC1 = TC1\n",
    "        self.TC2 = TC2\n",
    "        self.TC3 = TC3\n",
    "        self.TNB = TNB\n",
    "\n",
    "        self.SC1 = SC1\n",
    "        self.SC2 = SC2\n",
    "        self.SC3 = SC3\n",
    "        self.SNB = SNB\n",
    "\n",
    "    def forward(self, X, A_q, A_h):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_timesteps, num_nodes)\n",
    "        :A_hat: The Laplacian matrix (num_nodes, num_nodes)\n",
    "        :return: Reconstructed X of shape (batch_size, num_timesteps, num_nodes)\n",
    "        \"\"\"  \n",
    "        X = X[:,:,:,0] # Dummy dimension deleted\n",
    "        X_T = X.permute(0,2,1)\n",
    "        X_t1 = self.TC1(X_T)\n",
    "        X_t2 = self.TC2(X_t1) #num_time, rank\n",
    "        self.temporal_factors = X_t2\n",
    "        X_t3 = self.TC3(X_t2)\n",
    "        _b,_h,_ht = X_t3.shape\n",
    "        n_t_nb,p_t_nb = self.TNB(X_t3.view(_b,_h,_ht,1))\n",
    "\n",
    "        X_s1 = self.SC1(X, A_q, A_h)\n",
    "        X_s2 = self.SC2(X_s1, A_q, A_h) #num_nodes, rank\n",
    "        self.space_factors = X_s2\n",
    "        X_s3 = self.SC3(X_s2, A_q, A_h)\n",
    "        _b,_n,_hs = X_s3.shape\n",
    "        n_s_nb,p_s_nb = self.SNB(X_s3.view(_b,_n,_hs,1))\n",
    "        n_res = n_t_nb.permute(0, 2, 1) * n_s_nb\n",
    "        p_res = p_t_nb.permute(0, 2, 1) * p_s_nb\n",
    "               \n",
    "        return n_res,p_res\n",
    "\n",
    "class ST_Gau(nn.Module):\n",
    "    \"\"\"\n",
    "  wx_t  + wx_s\n",
    "    |       |\n",
    "   TC4     SC4\n",
    "    |       |\n",
    "   TC3     SC3\n",
    "    |       |\n",
    "   z_t     z_s\n",
    "    |       |\n",
    "   TC2     SC2\n",
    "    |       |  \n",
    "   TC1     SC1\n",
    "    |       |\n",
    "   x_m     x_m\n",
    "    \"\"\"\n",
    "    def __init__(self, SC1, SC2, SC3, TC1, TC2, TC3, SGau,TGau): \n",
    "        super(ST_Gau, self).__init__()\n",
    "        self.TC1 = TC1\n",
    "        self.TC2 = TC2\n",
    "        self.TC3 = TC3\n",
    "        self.TGau = TGau\n",
    "\n",
    "        self.SC1 = SC1\n",
    "        self.SC2 = SC2\n",
    "        self.SC3 = SC3\n",
    "        self.SGau = SGau\n",
    "\n",
    "    def forward(self, X, A_q, A_h):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_timesteps, num_nodes)\n",
    "        :A_hat: The Laplacian matrix (num_nodes, num_nodes)\n",
    "        :return: Reconstructed X of shape (batch_size, num_timesteps, num_nodes)\n",
    "        \"\"\"  \n",
    "        X = X[:,:,:,0] #.to(device='cuda') # Dummy dimension deleted\n",
    "        X_T = X.permute(0,2,1)\n",
    "        X_t1 = self.TC1(X_T)\n",
    "        X_t2 = self.TC2(X_t1) #num_time, rank\n",
    "        self.temporal_factors = X_t2\n",
    "        X_t3 = self.TC3(X_t2)\n",
    "        _b,_h,_ht = X_t3.shape\n",
    "        loc_t,scale_t = self.TGau(X_t3.view(_b,_h,_ht,1))\n",
    "\n",
    "        X_s1 = self.SC1(X, A_q, A_h)\n",
    "        X_s2 = self.SC2(X_s1, A_q, A_h) #num_nodes, rank\n",
    "        self.space_factors = X_s2\n",
    "        X_s3 = self.SC3(X_s2, A_q, A_h)\n",
    "        _b,_n,_hs = X_s3.shape\n",
    "        loc_s,scale_s = self.SGau(X_s3.view(_b,_n,_hs,1))\n",
    "\n",
    "        loc_res = loc_t.permute(0, 2, 1) * loc_s\n",
    "        scale_res = scale_t.permute(0, 2, 1) * scale_s\n",
    "               \n",
    "        return loc_res,scale_res\n",
    "\n",
    "class ST_NB_ZeroInflated(nn.Module):\n",
    "    \"\"\"\n",
    "  wx_t  + wx_s\n",
    "    |       |\n",
    "   TC4     SC4\n",
    "    |       |\n",
    "   TC3     SC3\n",
    "    |       |\n",
    "   z_t     z_s\n",
    "    |       |\n",
    "   TC2     SC2\n",
    "    |       |  \n",
    "   TC1     SC1\n",
    "    |       |\n",
    "   x_m     x_m\n",
    "    \"\"\"\n",
    "    def __init__(self, SC1, SC2, SC3, TC1, TC2, TC3, SNB,TNB): \n",
    "        super(ST_NB_ZeroInflated, self).__init__()\n",
    "        self.TC1 = TC1\n",
    "        self.TC2 = TC2\n",
    "        self.TC3 = TC3\n",
    "        self.TNB = TNB\n",
    "\n",
    "        self.SC1 = SC1\n",
    "        self.SC2 = SC2\n",
    "        self.SC3 = SC3\n",
    "        self.SNB = SNB\n",
    "\n",
    "    def forward(self, X, A_q, A_h):\n",
    "        \"\"\"\n",
    "        :param X: Input data of shape (batch_size, num_timesteps, num_nodes)\n",
    "        :A_hat: The Laplacian matrix (num_nodes, num_nodes)\n",
    "        :return: Reconstructed X of shape (batch_size, num_timesteps, num_nodes)\n",
    "        \"\"\"  \n",
    "        X = X[:,:,:,0]#.to(device='cuda') # Dummy dimension deleted\n",
    "        X_T = X.permute(0,2,1)\n",
    "        X_t1 = self.TC1(X_T)\n",
    "        X_t2 = self.TC2(X_t1) #num_time, rank\n",
    "        self.temporal_factors = X_t2\n",
    "        X_t3 = self.TC3(X_t2)\n",
    "        _b,_h,_ht = X_t3.shape\n",
    "        n_t_nb,p_t_nb,pi_t_nb = self.TNB(X_t3.view(_b,_h,_ht,1))\n",
    "\n",
    "        X_s1 = self.SC1(X, A_q, A_h)\n",
    "        X_s2 = self.SC2(X_s1, A_q, A_h) #num_nodes, rank\n",
    "        self.space_factors = X_s2\n",
    "        X_s3 = self.SC3(X_s2, A_q, A_h)\n",
    "        _b,_n,_hs = X_s3.shape\n",
    "        n_s_nb,p_s_nb,pi_s_nb = self.SNB(X_s3.view(_b,_n,_hs,1))\n",
    "        n_res = n_t_nb.permute(0, 2, 1) * n_s_nb\n",
    "        p_res = p_t_nb.permute(0, 2, 1) * p_s_nb\n",
    "        pi_res = pi_t_nb.permute(0, 2, 1) * pi_s_nb\n",
    "\n",
    "        return n_res,p_res,pi_res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "# from sklearn.externals import joblib\n",
    "import joblib\n",
    "import scipy.io\n",
    "import torch\n",
    "from torch import nn\n",
    "from scipy.stats import nbinom,norm\n",
    "rand = np.random.RandomState(0)\n",
    "\"\"\"\n",
    "Geographical information calculation\n",
    "\"\"\"\n",
    "def get_long_lat(sensor_index,loc = None):\n",
    "    \"\"\"\n",
    "        Input the index out from 0-206 to access the longitude and latitude of the nodes\n",
    "    \"\"\"\n",
    "    if loc is None:\n",
    "        locations = pd.read_csv('data/metr/graph_sensor_locations.csv')\n",
    "    else:\n",
    "        locations = loc\n",
    "    lng = locations['longitude'].loc[sensor_index]\n",
    "    lat = locations['latitude'].loc[sensor_index]\n",
    "    return lng.to_numpy(),lat.to_numpy()\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2): \n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees)\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    " \n",
    "    # haversine\n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 \n",
    "    return c * r * 1000\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generate the training sample for forecasting task, same idea from STGCN\n",
    "\"\"\"\n",
    "\n",
    "def generate_dataset(X, num_timesteps_input, num_timesteps_output):\n",
    "    \"\"\"\n",
    "    Takes node features for the graph and divides them into multiple samples\n",
    "    along the time-axis by sliding a window of size (num_timesteps_input+\n",
    "    num_timesteps_output) across it in steps of 1.\n",
    "    :param X: Node features of shape (num_vertices, num_features,\n",
    "    num_timesteps)\n",
    "    :return:\n",
    "        - Node features divided into multiple samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_input).\n",
    "        - Node targets for the samples. Shape is\n",
    "          (num_samples, num_vertices, num_features, num_timesteps_output).\n",
    "    \"\"\"\n",
    "    # Generate the beginning index and the ending index of a sample, which\n",
    "    # contains (num_points_for_training + num_points_for_predicting) points\n",
    "    indices = [(i, i + (num_timesteps_input + num_timesteps_output)) for i\n",
    "               in range(X.shape[2] - (\n",
    "                num_timesteps_input + num_timesteps_output) + 1)]\n",
    "\n",
    "    # Save samples\n",
    "    features, target = [], []\n",
    "    for i, j in indices:\n",
    "        features.append(\n",
    "            X[:, :, i: i + num_timesteps_input].transpose(\n",
    "                (0, 2, 1)))\n",
    "        target.append(X[:, 0, i + num_timesteps_input: j])\n",
    "\n",
    "    return torch.from_numpy(np.array(features)), \\\n",
    "           torch.from_numpy(np.array(target))\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Dynamically construct the adjacent matrix\n",
    "\"\"\"\n",
    "\n",
    "def get_Laplace(A):\n",
    "    \"\"\"\n",
    "    Returns the laplacian adjacency matrix. This is for C_GCN\n",
    "    \"\"\"\n",
    "    if A[0, 0] == 1:\n",
    "        A = A - np.diag(np.ones(A.shape[0], dtype=np.float32)) # if the diag has been added by 1s\n",
    "    D = np.array(np.sum(A, axis=1)).reshape((-1,))\n",
    "    D[D <= 10e-5] = 10e-5\n",
    "    diag = np.reciprocal(np.sqrt(D))\n",
    "    A_wave = np.multiply(np.multiply(diag.reshape((-1, 1)), A),\n",
    "                         diag.reshape((1, -1)))\n",
    "    return A_wave\n",
    "\n",
    "def get_normalized_adj(A):\n",
    "    \"\"\"\n",
    "    Returns the degree normalized adjacency matrix. This is for K_GCN\n",
    "    \"\"\"\n",
    "    if A[0, 0] == 0:\n",
    "        A = A + np.diag(np.ones(A.shape[0], dtype=np.float32)) # if the diag has been added by 1s\n",
    "    D = np.array(np.sum(A, axis=1)).reshape((-1,))\n",
    "    D[D <= 10e-5] = 10e-5    # Prevent infs\n",
    "    diag = np.reciprocal(np.sqrt(D))\n",
    "    A_wave = np.multiply(np.multiply(diag.reshape((-1, 1)), A),\n",
    "                         diag.reshape((1, -1)))\n",
    "    return A_wave\n",
    "\n",
    "def calculate_random_walk_matrix(adj_mx):\n",
    "    \"\"\"\n",
    "    Returns the random walk adjacency matrix. This is for D_GCN\n",
    "    \"\"\"\n",
    "    adj_mx = sp.coo_matrix(adj_mx)\n",
    "    d = np.array(adj_mx.sum(1))\n",
    "    d_inv = np.power(d, -1).flatten()\n",
    "    d_inv[np.isinf(d_inv)] = 0.\n",
    "    d_mat_inv = sp.diags(d_inv)\n",
    "    random_walk_mx = d_mat_inv.dot(adj_mx).tocoo()\n",
    "    return random_walk_mx.toarray()\n",
    "\n",
    "\n",
    "def test_error_virtual(STmodel, unknow_set, test_data, A_s, E_maxvalue, Missing0):\n",
    "    \"\"\"\n",
    "    :param STmodel: The graph neural networks\n",
    "    :unknow_set: The unknow locations for spatial prediction\n",
    "    :test_data: The true value test_data of shape (test_num_timesteps, num_nodes)\n",
    "    :A_s: The full adjacent matrix\n",
    "    :Missing0: True: 0 in original datasets means missing data\n",
    "    :return: NAE, MAPE and RMSE\n",
    "    \"\"\"  \n",
    "    unknow_set = set(unknow_set)\n",
    "    time_dim = STmodel.time_dimension\n",
    "    \n",
    "    test_omask = np.ones(test_data.shape)\n",
    "    if Missing0 == True:\n",
    "        test_omask[test_data == 0] = 0\n",
    "    test_inputs = (test_data * test_omask).astype('float32')\n",
    "    test_inputs_s = test_inputs\n",
    "   \n",
    "    missing_index = np.ones(np.shape(test_data))\n",
    "    missing_index[:, list(unknow_set)] = 0\n",
    "    missing_index_s = missing_index\n",
    "    \n",
    "    o = np.zeros([test_data.shape[0]//time_dim*time_dim, test_inputs_s.shape[1]]) #Separate the test data into several h period\n",
    "    \n",
    "    for i in range(0, test_data.shape[0]//time_dim*time_dim, time_dim):\n",
    "        inputs = test_inputs_s[i:i+time_dim, :]\n",
    "        missing_inputs = missing_index_s[i:i+time_dim, :]\n",
    "        T_inputs = inputs*missing_inputs\n",
    "        T_inputs = T_inputs/E_maxvalue\n",
    "        T_inputs = np.expand_dims(T_inputs, axis = 0)\n",
    "        T_inputs = torch.from_numpy(T_inputs.astype('float32'))\n",
    "        A_q = torch.from_numpy((calculate_random_walk_matrix(A_s).T).astype('float32'))\n",
    "        A_h = torch.from_numpy((calculate_random_walk_matrix(A_s.T).T).astype('float32'))\n",
    "        \n",
    "        imputation = STmodel(T_inputs, A_q, A_h)\n",
    "        imputation = imputation.data.numpy()\n",
    "        o[i:i+time_dim, :] = imputation[0, :, :]\n",
    "    \n",
    "    o = o*E_maxvalue \n",
    "    truth = test_inputs_s[0:test_data.shape[0]//time_dim*time_dim]\n",
    "    o[missing_index_s[0:test_data.shape[0]//time_dim*time_dim] == 1] = truth[missing_index_s[0:test_data.shape[0]//time_dim*time_dim] == 1]\n",
    "    \n",
    "    test_mask =  1 - missing_index_s[0:test_data.shape[0]//time_dim*time_dim]\n",
    "    if Missing0 == True:\n",
    "        test_mask[truth == 0] = 0\n",
    "        o[truth == 0] = 0\n",
    "    \n",
    "    o_ = o[:,list(unknow_set)]\n",
    "    truth_ = truth[:,list(unknow_set)]\n",
    "    test_mask_ = test_mask[:,list(unknow_set)]\n",
    "\n",
    "    MAE = np.sum(np.abs(o_ - truth_))/np.sum( test_mask_)\n",
    "    RMSE = np.sqrt(np.sum((o_ - truth_)*(o_ - truth_))/np.sum( test_mask_) )\n",
    "    # MAPE = np.sum(np.abs(o - truth)/(truth + 1e-5))/np.sum( test_mask)\n",
    "    R2 = 1 - np.sum( (o_ - truth_)*(o_ - truth_) )/np.sum( (truth_ - truth_.mean())*(truth_-truth_.mean() ) )\n",
    "    print(truth_.mean())\n",
    "    return MAE, RMSE, R2, o\n",
    "\n",
    "def test_error(STmodel, unknow_set, test_data, A_s, E_maxvalue, Missing0):\n",
    "    \"\"\"\n",
    "    :param STmodel: The graph neural networks\n",
    "    :unknow_set: The unknow locations for spatial prediction\n",
    "    :test_data: The true value test_data of shape (test_num_timesteps, num_nodes)\n",
    "    :A_s: The full adjacent matrix\n",
    "    :Missing0: True: 0 in original datasets means missing data\n",
    "    :return: NAE, MAPE and RMSE\n",
    "    \"\"\"  \n",
    "    unknow_set = set(unknow_set)\n",
    "    time_dim = STmodel.time_dimension\n",
    "    \n",
    "    test_omask = np.ones(test_data.shape)\n",
    "    if Missing0 == True:\n",
    "        test_omask[test_data == 0] = 0\n",
    "    test_inputs = (test_data * test_omask).astype('float32')\n",
    "    test_inputs_s = test_inputs\n",
    "   \n",
    "    missing_index = np.ones(np.shape(test_data))\n",
    "    missing_index[:, list(unknow_set)] = 0\n",
    "    missing_index_s = missing_index\n",
    "    \n",
    "    o = np.zeros([test_data.shape[0]//time_dim*time_dim, test_inputs_s.shape[1]]) #Separate the test data into several h period\n",
    "    \n",
    "    for i in range(0, test_data.shape[0]//time_dim*time_dim, time_dim):\n",
    "        inputs = test_inputs_s[i:i+time_dim, :]\n",
    "        missing_inputs = missing_index_s[i:i+time_dim, :]\n",
    "        T_inputs = inputs*missing_inputs\n",
    "        T_inputs = T_inputs/E_maxvalue\n",
    "        T_inputs = np.expand_dims(T_inputs, axis = 0)\n",
    "        T_inputs = torch.from_numpy(T_inputs.astype('float32'))\n",
    "        A_q = torch.from_numpy((calculate_random_walk_matrix(A_s).T).astype('float32'))\n",
    "        A_h = torch.from_numpy((calculate_random_walk_matrix(A_s.T).T).astype('float32'))\n",
    "        \n",
    "        imputation = STmodel(T_inputs, A_q, A_h)\n",
    "        imputation = imputation.data.numpy()\n",
    "        o[i:i+time_dim, :] = imputation[0, :, :]\n",
    "    \n",
    "    o = o*E_maxvalue \n",
    "    truth = test_inputs_s[0:test_data.shape[0]//time_dim*time_dim]\n",
    "    o[missing_index_s[0:test_data.shape[0]//time_dim*time_dim] == 1] = truth[missing_index_s[0:test_data.shape[0]//time_dim*time_dim] == 1]\n",
    "    \n",
    "    test_mask =  1 - missing_index_s[0:test_data.shape[0]//time_dim*time_dim]\n",
    "    if Missing0 == True:\n",
    "        test_mask[truth == 0] = 0\n",
    "        o[truth == 0] = 0\n",
    "    \n",
    "    o_ = o[:,list(unknow_set)]\n",
    "    truth_ = truth[:,list(unknow_set)]\n",
    "    test_mask_ = test_mask[:,list(unknow_set)]\n",
    "\n",
    "    MAE = np.sum(np.abs(o_ - truth_))/np.sum( test_mask_)\n",
    "    RMSE = np.sqrt(np.sum((o_ - truth_)*(o_ - truth_))/np.sum( test_mask_) )\n",
    "    # MAPE = np.sum(np.abs(o - truth)/(truth + 1e-5))/np.sum( test_mask)\n",
    "    R2 = 1 - np.sum( (o_ - truth_)*(o_ - truth_) )/np.sum( (truth_ - truth_.mean())*(truth_-truth_.mean() ) )\n",
    "    print(truth_.mean())\n",
    "    return MAE, RMSE, R2, o\n",
    "\n",
    "\n",
    "def rolling_test_error(STmodel, unknow_set, test_data, A_s, E_maxvalue,Missing0):\n",
    "    \"\"\"\n",
    "    :It only calculates the last time points' prediction error, and updates inputs each time point\n",
    "    :param STmodel: The graph neural networks\n",
    "    :unknow_set: The unknow locations for spatial prediction\n",
    "    :test_data: The true value test_data of shape (test_num_timesteps, num_nodes)\n",
    "    :A_s: The full adjacent matrix\n",
    "    :Missing0: True: 0 in original datasets means missing data\n",
    "    :return: NAE, MAPE and RMSE\n",
    "    \"\"\"  \n",
    "    \n",
    "    unknow_set = set(unknow_set)\n",
    "    time_dim = STmodel.time_dimension\n",
    "    \n",
    "    test_omask = np.ones(test_data.shape)\n",
    "    if Missing0 == True:\n",
    "        test_omask[test_data == 0] = 0\n",
    "    test_inputs = (test_data * test_omask).astype('float32')\n",
    "    test_inputs_s = test_inputs\n",
    "   \n",
    "    missing_index = np.ones(np.shape(test_data))\n",
    "    missing_index[:, list(unknow_set)] = 0\n",
    "    missing_index_s = missing_index\n",
    "\n",
    "    o = np.zeros([test_data.shape[0] - time_dim, test_inputs_s.shape[1]])\n",
    "    \n",
    "    for i in range(0, test_data.shape[0] - time_dim):\n",
    "        inputs = test_inputs_s[i:i+time_dim, :]\n",
    "        missing_inputs = missing_index_s[i:i+time_dim, :]\n",
    "        MF_inputs = inputs * missing_inputs\n",
    "        MF_inputs = np.expand_dims(MF_inputs, axis = 0)\n",
    "        MF_inputs = torch.from_numpy(MF_inputs.astype('float32'))\n",
    "        A_q = torch.from_numpy((calculate_random_walk_matrix(A_s).T).astype('float32'))\n",
    "        A_h = torch.from_numpy((calculate_random_walk_matrix(A_s.T).T).astype('float32'))\n",
    "        \n",
    "        imputation = STmodel(MF_inputs, A_q, A_h)\n",
    "        imputation = imputation.data.numpy()\n",
    "        o[i, :] = imputation[0, time_dim-1, :]\n",
    "    \n",
    " \n",
    "    truth = test_inputs_s[time_dim:test_data.shape[0]]\n",
    "    o[missing_index_s[time_dim:test_data.shape[0]] == 1] = truth[missing_index_s[time_dim:test_data.shape[0]] == 1]\n",
    "    \n",
    "    o = o*E_maxvalue\n",
    "    truth = test_inputs_s[0:test_data.shape[0]//time_dim*time_dim]\n",
    "    test_mask =  1 - missing_index_s[time_dim:test_data.shape[0]]\n",
    "    if Missing0 == True:\n",
    "        test_mask[truth == 0] = 0\n",
    "        o[truth == 0] = 0\n",
    "        \n",
    "    MAE = np.sum(np.abs(o - truth))/np.sum( test_mask)\n",
    "    RMSE = np.sqrt(np.sum((o - truth)*(o - truth))/np.sum( test_mask) )\n",
    "    MAPE = np.sum(np.abs(o - truth)/(truth + 1e-5))/np.sum( test_mask)  #avoid x/0\n",
    "        \n",
    "    return MAE, RMSE, MAPE, o\n",
    "\n",
    "def test_error_cap(STmodel, unknow_set, full_set, test_set, A,time_dim,capacities):\n",
    "    unknow_set = set(unknow_set)\n",
    "    \n",
    "    test_omask = np.ones(test_set.shape)\n",
    "    test_omask[test_set == 0] = 0\n",
    "    test_inputs = (test_set * test_omask).astype('float32')\n",
    "    test_inputs_s = test_inputs#[:, list(proc_set)]\n",
    "\n",
    "    \n",
    "    missing_index = np.ones(np.shape(test_inputs))\n",
    "    missing_index[:, list(unknow_set)] = 0\n",
    "    missing_index_s = missing_index#[:, list(proc_set)]\n",
    "    \n",
    "    A_s = A#[:, list(proc_set)][list(proc_set), :]\n",
    "    o = np.zeros([test_set.shape[0]//time_dim*time_dim, test_inputs_s.shape[1]])\n",
    "    \n",
    "    for i in range(0, test_set.shape[0]//time_dim*time_dim, time_dim):\n",
    "        inputs = test_inputs_s[i:i+time_dim, :]\n",
    "        missing_inputs = missing_index_s[i:i+time_dim, :]\n",
    "        MF_inputs = inputs*missing_inputs\n",
    "        MF_inputs = MF_inputs\n",
    "        MF_inputs = np.expand_dims(MF_inputs, axis = 0)\n",
    "        MF_inputs = torch.from_numpy(MF_inputs.astype('float32'))\n",
    "        A_q = torch.from_numpy((calculate_random_walk_matrix(A_s).T).astype('float32'))\n",
    "        A_h = torch.from_numpy((calculate_random_walk_matrix(A_s.T).T).astype('float32'))\n",
    "        \n",
    "        imputation = STmodel(MF_inputs, A_q, A_h)\n",
    "        imputation = imputation.data.numpy()\n",
    "        o[i:i+time_dim, :] = imputation[0, :, :]\n",
    "    \n",
    "    o = o*capacities\n",
    "    truth = test_inputs_s[0:test_set.shape[0]//time_dim*time_dim]\n",
    "    truth = truth*capacities\n",
    "    o[missing_index_s[0:test_set.shape[0]//time_dim*time_dim] == 1] = truth[missing_index_s[0:test_set.shape[0]//time_dim*time_dim] == 1]\n",
    "    o[truth == 0] = 0\n",
    "    \n",
    "    test_mask =  1 - missing_index_s[0:test_set.shape[0]//time_dim*time_dim]\n",
    "    test_mask[truth == 0] = 0\n",
    "    \n",
    "    o_ = o[:,list(unknow_set)]\n",
    "    truth_ = truth[:,list(unknow_set)]\n",
    "    test_mask_ = test_mask[:,list(unknow_set)]\n",
    "\n",
    "    MAE = np.sum(np.abs(o_ - truth_))/np.sum( test_mask_)\n",
    "    RMSE = np.sqrt(np.sum((o_ - truth_)*(o_ - truth_))/np.sum( test_mask_) )\n",
    "    # MAPE = np.sum(np.abs(o - truth)/(truth + 1e-5))/np.sum( test_mask)\n",
    "    R2 = 1 - np.sum( (o_ - truth_)*(o_ - truth_) )/np.sum( (truth_ - truth_.mean())*(truth_-truth_.mean() ) )\n",
    "    print(truth_.mean())\n",
    "    return MAE, RMSE, R2, o\n",
    "\n",
    "def nb_nll_loss(y,n,p,y_mask=None):\n",
    "    \"\"\"\n",
    "    y: true values\n",
    "    y_mask: whether missing mask is given\n",
    "    \"\"\"\n",
    "    nll = torch.lgamma(n) + torch.lgamma(y+1) - torch.lgamma(n+y) - n*torch.log(p) - y*torch.log(1-p)\n",
    "    if y_mask is not None:\n",
    "        nll = nll*y_mask\n",
    "    return torch.sum(nll)\n",
    "\n",
    "def nb_zeroinflated_nll_loss(y,n,p,pi,y_mask=None):\n",
    "    \"\"\"\n",
    "    y: true values\n",
    "    y_mask: whether missing mask is given\n",
    "    https://stats.idre.ucla.edu/r/dae/zinb/\n",
    "    \"\"\"\n",
    "    idx_yeq0 = y==0\n",
    "    idx_yg0  = y>0\n",
    "    \n",
    "    n_yeq0 = n[idx_yeq0]\n",
    "    p_yeq0 = p[idx_yeq0]\n",
    "    pi_yeq0 = pi[idx_yeq0]\n",
    "    yeq0 = y[idx_yeq0]\n",
    "\n",
    "    n_yg0 = n[idx_yg0]\n",
    "    p_yg0 = p[idx_yg0]\n",
    "    pi_yg0 = pi[idx_yg0]\n",
    "    yg0 = y[idx_yg0]\n",
    "\n",
    "    #L_yeq0 = torch.log(pi_yeq0) + (1-pi_yeq0)*torch.pow(p_yeq0,n_yeq0)\n",
    "    #L_yg0  = torch.log(pi_yg0) + torch.lgamma(n_yg0+yg0) - torch.lgamma(yg0+1) - torch.lgamma(n_yg0) + n_yg0*torch.log(p_yg0) + yg0*torch.log(1-p_yg0)\n",
    "    L_yeq0 = torch.log(pi_yeq0) + torch.log( (1-pi_yeq0)*torch.pow(p_yeq0,n_yeq0))\n",
    "    L_yg0  = torch.log(1-pi_yg0) + torch.lgamma(n_yg0+yg0) - torch.lgamma(yg0+1) - torch.lgamma(n_yg0) + n_yg0*torch.log(p_yg0) + yg0*torch.log(1-p_yg0)\n",
    "    #print('nll',torch.mean(L_yeq0),torch.mean(L_yg0),torch.mean(torch.log(pi_yeq0)),torch.mean(torch.log(pi_yg0)))\n",
    "    return -torch.sum(L_yeq0)-torch.sum(L_yg0)\n",
    "\n",
    "def nb_zeroinflated_draw(n,p,pi):\n",
    "    \"\"\"\n",
    "    input: n, p, pi tensors\n",
    "    output: drawn values\n",
    "    \"\"\"\n",
    "    origin_shape = n.shape\n",
    "    n = n.flatten()\n",
    "    p = p.flatten()\n",
    "    pi = pi.flatten()\n",
    "    nb = nbinom(n,p)\n",
    "    x_low = nb.ppf(0.01)\n",
    "    x_up  = nb.ppf(0.99)\n",
    "    pred = np.zeros_like(n)\n",
    "   # print(n.shape,x_low.shape,pi.min())\n",
    "    for i in range(len(x_low)):\n",
    "        if x_up[i]<=1:\n",
    "            x_up[i] = 1\n",
    "        x = np.arange(x_low[i],x_up[i])\n",
    "        #print(pi[0],pi[0].shape,x.shape,pi.shape)\n",
    "        prob = (1-pi[i]) * nbinom.pmf(x,n[i],p[i])\n",
    "#        print(len(prob),len(pi),len(n),len(x))\n",
    "        prob[0] += pi[i] # zero-inflatted\n",
    "        pred[i] = rand.choice(a=x,p=prob/np.sum(prob)) # random seed fixed, defined in the beginning\n",
    "\n",
    "    return pred.reshape(origin_shape)\n",
    "\n",
    "def gauss_draw(loc,scale):\n",
    "    \"\"\"\n",
    "    input: n, p, pi tensors\n",
    "    output: drawn values\n",
    "    \"\"\"\n",
    "    origin_shape = loc.shape\n",
    "    loc = loc.flatten()\n",
    "    scale = scale.flatten()\n",
    "    gauss = norm(loc,scale)\n",
    "    x_low = gauss.ppf(0.01)\n",
    "    x_up  = gauss.ppf(0.99)\n",
    "    pred = np.zeros_like(loc)\n",
    "    #print(n.shape,x_low.shape,pi.min())\n",
    "    for i in range(len(x_low)):\n",
    "        x = np.arange(x_low[i],x_up[i],100)\n",
    "        prob = norm.pdf(x,loc[i],scale[i])\n",
    "        pred[i] = rand.choice(a=x,p=prob/np.sum(prob)) # random seed fixed, defined in the beginning\n",
    "\n",
    "    return pred.reshape(origin_shape)\n",
    "\n",
    "def nb_draw(n,p):\n",
    "    \"\"\"\n",
    "    input: n, p, pi tensors\n",
    "    output: drawn values\n",
    "    \"\"\"\n",
    "    origin_shape = n.shape\n",
    "    n = n.flatten()\n",
    "    p = p.flatten()\n",
    "    nb = nbinom(n,p)\n",
    "    x_low = nb.ppf(0.01)\n",
    "    x_up  = nb.ppf(0.99)\n",
    "    pred = np.zeros_like(n)\n",
    "    for i in range(len(x_low)):\n",
    "        if x_up[i]<=1:\n",
    "            x_up[i] = 1\n",
    "        if x_up[i] == x_low[i]:\n",
    "            x_up[i] = x_low[i]+1\n",
    "        #print(x_low[i],x_up[i])\n",
    "        x = np.arange(x_low[i],x_up[i])\n",
    "        prob = nbinom.pmf(x,n[i],p[i])\n",
    "        pred[i] = rand.choice(a=x,p=prob/np.sum(prob)) # random seed fixed, defined in the beginning\n",
    "\n",
    "    return pred.reshape(origin_shape)\n",
    "\n",
    "def gauss_loss(y,loc,scale,y_mask=None):\n",
    "    \"\"\"\n",
    "    The location (loc) keyword specifies the mean. The scale (scale) keyword specifies the standard deviation.\n",
    "    http://jrmeyer.github.io/machinelearning/2017/08/18/mle.html\n",
    "    \"\"\"\n",
    "    torch.pi = torch.acos(torch.zeros(1)).item() * 2 # ugly define pi value in torch format\n",
    "    LL = -1/2 * torch.log(2*torch.pi*torch.pow(scale,2)) - 1/2*( torch.pow(y-loc,2)/torch.pow(scale,2) )\n",
    "    return -torch.sum(LL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4489, 1, 2880) (4489, 4489)\n",
      "input shape:  torch.Size([1721, 4489, 4, 1]) torch.Size([280, 4489, 4, 1]) torch.Size([858, 4489, 4, 1])\n",
      "Pi_val,mean,min,max tensor(0.2902, device='cuda:0') tensor(0.0024, device='cuda:0') tensor(0.5438, device='cuda:0')\n",
      "1.2339737 0.0024461884\n",
      "Epoch: 0\n",
      "Training loss: 195635.73970417635\n",
      "Epoch 0: trainNLL 195635.73970; valNLL 13391688.00000; MAE 1.8101; RMSE 3.3610\n",
      "Pi_val,mean,min,max tensor(0.3046, device='cuda:0') tensor(0.0005, device='cuda:0') tensor(0.5468, device='cuda:0')\n",
      "1.3423146 0.0005042944\n",
      "Epoch: 1\n",
      "Training loss: 187458.7440998405\n",
      "Epoch 1: trainNLL 187458.74410; valNLL 12919113.00000; MAE 1.6522; RMSE 3.2789\n",
      "Pi_val,mean,min,max tensor(0.3050, device='cuda:0') tensor(6.2064e-05, device='cuda:0') tensor(0.5484, device='cuda:0')\n",
      "1.4268064 6.206427e-05\n",
      "Epoch: 2\n",
      "Training loss: 181910.02844040023\n",
      "Epoch 2: trainNLL 181910.02844; valNLL 12619295.00000; MAE 1.5975; RMSE 4.1109\n",
      "Pi_val,mean,min,max tensor(0.3001, device='cuda:0') tensor(1.1386e-05, device='cuda:0') tensor(0.5726, device='cuda:0')\n",
      "1.5180225 1.1386205e-05\n",
      "Epoch: 3\n",
      "Training loss: 178392.38938333816\n",
      "Epoch 3: trainNLL 178392.38938; valNLL 12397454.00000; MAE 1.5270; RMSE 3.2570\n",
      "Pi_val,mean,min,max tensor(0.2962, device='cuda:0') tensor(1.2145e-06, device='cuda:0') tensor(0.5891, device='cuda:0')\n",
      "1.5042087 1.2144654e-06\n",
      "Epoch: 4\n",
      "Training loss: 175624.3674412703\n",
      "Epoch 4: trainNLL 175624.36744; valNLL 12221878.00000; MAE 1.4607; RMSE 2.8447\n",
      "Pi_val,mean,min,max tensor(0.2968, device='cuda:0') tensor(1.6829e-07, device='cuda:0') tensor(0.6035, device='cuda:0')\n",
      "1.48324 1.6828604e-07\n",
      "Epoch: 5\n",
      "Training loss: 173420.68076602378\n",
      "Epoch 5: trainNLL 173420.68077; valNLL 12085022.00000; MAE 1.4172; RMSE 2.7526\n",
      "Pi_val,mean,min,max tensor(0.2914, device='cuda:0') tensor(3.6750e-08, device='cuda:0') tensor(0.6672, device='cuda:0')\n",
      "1.6154253 3.6750475e-08\n",
      "Epoch: 6\n",
      "Training loss: 171662.05069968099\n",
      "Epoch 6: trainNLL 171662.05070; valNLL 11977638.00000; MAE 1.4078; RMSE 2.7052\n",
      "Pi_val,mean,min,max tensor(0.2935, device='cuda:0') tensor(1.3180e-08, device='cuda:0') tensor(0.6676, device='cuda:0')\n",
      "1.5656204 1.3180025e-08\n",
      "Epoch: 7\n",
      "Training loss: 170243.1610988254\n",
      "Epoch 7: trainNLL 170243.16110; valNLL 11881438.00000; MAE 1.3746; RMSE 2.6647\n",
      "Pi_val,mean,min,max tensor(0.2940, device='cuda:0') tensor(5.4557e-09, device='cuda:0') tensor(0.6793, device='cuda:0')\n",
      "1.549489 5.4557403e-09\n",
      "Epoch: 8\n",
      "Training loss: 169035.96786180395\n",
      "Epoch 8: trainNLL 169035.96786; valNLL 11803848.00000; MAE 1.3525; RMSE 2.6355\n",
      "Pi_val,mean,min,max tensor(0.2950, device='cuda:0') tensor(1.2522e-09, device='cuda:0') tensor(0.6947, device='cuda:0')\n",
      "1.571688 1.2522459e-09\n",
      "Epoch: 9\n",
      "Training loss: 168004.2907210702\n",
      "Epoch 9: trainNLL 168004.29072; valNLL 11738150.00000; MAE 1.3384; RMSE 2.6166\n",
      "Pi_val,mean,min,max tensor(0.2943, device='cuda:0') tensor(3.4985e-10, device='cuda:0') tensor(0.7131, device='cuda:0')\n",
      "1.5890926 3.4985287e-10\n",
      "Epoch: 10\n",
      "Training loss: 167119.43929451855\n",
      "Epoch 10: trainNLL 167119.43929; valNLL 11682313.00000; MAE 1.3254; RMSE 2.5936\n",
      "Pi_val,mean,min,max tensor(0.2966, device='cuda:0') tensor(1.3049e-10, device='cuda:0') tensor(0.7312, device='cuda:0')\n",
      "1.5949947 1.3048962e-10\n",
      "Epoch: 11\n",
      "Training loss: 166354.25118728247\n",
      "Epoch 11: trainNLL 166354.25119; valNLL 11633602.00000; MAE 1.3134; RMSE 2.5770\n",
      "Pi_val,mean,min,max tensor(0.2965, device='cuda:0') tensor(6.1783e-11, device='cuda:0') tensor(0.7548, device='cuda:0')\n",
      "1.6100181 6.178333e-11\n",
      "Epoch: 12\n",
      "Training loss: 165684.53429524362\n",
      "Epoch 12: trainNLL 165684.53430; valNLL 11592630.00000; MAE 1.3034; RMSE 2.5617\n",
      "Pi_val,mean,min,max tensor(0.2982, device='cuda:0') tensor(3.5130e-11, device='cuda:0') tensor(0.7676, device='cuda:0')\n",
      "1.5764718 3.5130135e-11\n",
      "Epoch: 13\n",
      "Training loss: 165084.48930539444\n",
      "Epoch 13: trainNLL 165084.48931; valNLL 11554044.00000; MAE 1.2862; RMSE 2.5384\n",
      "Pi_val,mean,min,max tensor(0.2986, device='cuda:0') tensor(2.4212e-11, device='cuda:0') tensor(0.7803, device='cuda:0')\n",
      "1.6026598 2.421191e-11\n",
      "Epoch: 14\n",
      "Training loss: 164545.8864287268\n",
      "Epoch 14: trainNLL 164545.88643; valNLL 11520470.00000; MAE 1.2797; RMSE 2.5211\n",
      "Pi_val,mean,min,max tensor(0.3006, device='cuda:0') tensor(1.7746e-11, device='cuda:0') tensor(0.7803, device='cuda:0')\n",
      "1.598264 1.774561e-11\n",
      "Epoch: 15\n",
      "Training loss: 164047.23191886602\n",
      "Epoch 15: trainNLL 164047.23192; valNLL 11487218.00000; MAE 1.2688; RMSE 2.5040\n",
      "Pi_val,mean,min,max tensor(0.2960, device='cuda:0') tensor(1.4354e-11, device='cuda:0') tensor(0.7817, device='cuda:0')\n",
      "1.6368691 1.43538645e-11\n",
      "Epoch: 16\n",
      "Training loss: 163576.92774796984\n",
      "Epoch 16: trainNLL 163576.92775; valNLL 11457544.00000; MAE 1.2652; RMSE 2.4874\n",
      "Pi_val,mean,min,max tensor(0.3050, device='cuda:0') tensor(1.6007e-11, device='cuda:0') tensor(0.7876, device='cuda:0')\n",
      "1.5668058 1.6006923e-11\n",
      "Epoch: 17\n",
      "Training loss: 163107.84261709687\n",
      "Epoch 17: trainNLL 163107.84262; valNLL 11435252.00000; MAE 1.2488; RMSE 2.4878\n",
      "Pi_val,mean,min,max tensor(0.3016, device='cuda:0') tensor(1.4194e-11, device='cuda:0') tensor(0.7952, device='cuda:0')\n",
      "1.572706 1.419381e-11\n",
      "Epoch: 18\n",
      "Training loss: 162730.41125290023\n",
      "Epoch 18: trainNLL 162730.41125; valNLL 11404688.00000; MAE 1.2398; RMSE 2.4670\n",
      "Pi_val,mean,min,max tensor(0.2992, device='cuda:0') tensor(1.4742e-11, device='cuda:0') tensor(0.7847, device='cuda:0')\n",
      "1.632396 1.4742058e-11\n",
      "Epoch: 19\n",
      "Training loss: 162350.11735970128\n",
      "Epoch 19: trainNLL 162350.11736; valNLL 11376714.00000; MAE 1.2385; RMSE 2.4441\n",
      "Pi_val,mean,min,max tensor(0.2982, device='cuda:0') tensor(1.3756e-11, device='cuda:0') tensor(0.7751, device='cuda:0')\n",
      "1.6646594 1.3756106e-11\n",
      "Epoch: 20\n",
      "Training loss: 161958.98725710556\n",
      "Epoch 20: trainNLL 161958.98726; valNLL 11351800.00000; MAE 1.2352; RMSE 2.4330\n",
      "Pi_val,mean,min,max tensor(0.3008, device='cuda:0') tensor(1.5384e-11, device='cuda:0') tensor(0.8126, device='cuda:0')\n",
      "1.6479752 1.5383802e-11\n",
      "Epoch: 21\n",
      "Training loss: 161610.78492966937\n",
      "Epoch 21: trainNLL 161610.78493; valNLL 11330792.00000; MAE 1.2253; RMSE 2.4260\n",
      "Pi_val,mean,min,max tensor(0.3030, device='cuda:0') tensor(1.7371e-11, device='cuda:0') tensor(0.7987, device='cuda:0')\n",
      "1.6009133 1.7371111e-11\n",
      "Epoch: 22\n",
      "Training loss: 161247.2339399652\n",
      "Epoch 22: trainNLL 161247.23394; valNLL 11305771.00000; MAE 1.2098; RMSE 2.4057\n",
      "Pi_val,mean,min,max tensor(0.3008, device='cuda:0') tensor(2.0910e-11, device='cuda:0') tensor(0.7951, device='cuda:0')\n",
      "1.6476209 2.0909769e-11\n",
      "Epoch: 23\n",
      "Training loss: 160917.09255365428\n",
      "Epoch 23: trainNLL 160917.09255; valNLL 11283944.00000; MAE 1.2105; RMSE 2.3952\n",
      "Pi_val,mean,min,max tensor(0.2981, device='cuda:0') tensor(2.1606e-11, device='cuda:0') tensor(0.7990, device='cuda:0')\n",
      "1.689019 2.1605752e-11\n",
      "Epoch: 24\n",
      "Training loss: 160601.33176841648\n",
      "Epoch 24: trainNLL 160601.33177; valNLL 11262728.00000; MAE 1.2088; RMSE 2.3811\n",
      "Pi_val,mean,min,max tensor(0.2994, device='cuda:0') tensor(2.7702e-11, device='cuda:0') tensor(0.8060, device='cuda:0')\n",
      "1.6796174 2.770189e-11\n",
      "Epoch: 25\n",
      "Training loss: 160279.05452436194\n",
      "Epoch 25: trainNLL 160279.05452; valNLL 11242424.00000; MAE 1.2016; RMSE 2.3714\n",
      "Pi_val,mean,min,max tensor(0.3027, device='cuda:0') tensor(3.2911e-11, device='cuda:0') tensor(0.8094, device='cuda:0')\n",
      "1.65864 3.291057e-11\n",
      "Epoch: 26\n",
      "Training loss: 159967.6360344765\n",
      "Epoch 26: trainNLL 159967.63603; valNLL 11223898.00000; MAE 1.1932; RMSE 2.3652\n",
      "Pi_val,mean,min,max tensor(0.2978, device='cuda:0') tensor(3.5808e-11, device='cuda:0') tensor(0.8038, device='cuda:0')\n",
      "1.6997421 3.5807732e-11\n",
      "Epoch: 27\n",
      "Training loss: 159672.4118148202\n",
      "Epoch 27: trainNLL 159672.41181; valNLL 11201438.00000; MAE 1.1904; RMSE 2.3425\n",
      "Pi_val,mean,min,max tensor(0.2965, device='cuda:0') tensor(4.0113e-11, device='cuda:0') tensor(0.8107, device='cuda:0')\n",
      "1.7323822 4.0113156e-11\n",
      "Epoch: 28\n",
      "Training loss: 159368.2234447506\n",
      "Epoch 28: trainNLL 159368.22344; valNLL 11184709.00000; MAE 1.1892; RMSE 2.3321\n",
      "Pi_val,mean,min,max tensor(0.3021, device='cuda:0') tensor(4.8011e-11, device='cuda:0') tensor(0.8192, device='cuda:0')\n",
      "1.6448727 4.801093e-11\n",
      "Epoch: 29\n",
      "Training loss: 159107.0431046984\n",
      "Epoch 29: trainNLL 159107.04310; valNLL 11163616.00000; MAE 1.1712; RMSE 2.3265\n",
      "Pi_val,mean,min,max tensor(0.2991, device='cuda:0') tensor(5.2527e-11, device='cuda:0') tensor(0.8055, device='cuda:0')\n",
      "1.667537 5.2527125e-11\n",
      "Epoch: 30\n",
      "Training loss: 158840.361187645\n",
      "Epoch 30: trainNLL 158840.36119; valNLL 11145677.00000; MAE 1.1695; RMSE 2.3152\n",
      "Pi_val,mean,min,max tensor(0.2964, device='cuda:0') tensor(5.7562e-11, device='cuda:0') tensor(0.8152, device='cuda:0')\n",
      "1.7317319 5.7561914e-11\n",
      "Epoch: 31\n",
      "Training loss: 158571.7733649942\n",
      "Epoch 31: trainNLL 158571.77336; valNLL 11130619.00000; MAE 1.1728; RMSE 2.3033\n",
      "Pi_val,mean,min,max tensor(0.2989, device='cuda:0') tensor(5.8119e-11, device='cuda:0') tensor(0.8284, device='cuda:0')\n",
      "1.7125014 5.8119256e-11\n",
      "Epoch: 32\n",
      "Training loss: 158309.64480767836\n",
      "Epoch 32: trainNLL 158309.64481; valNLL 11112502.00000; MAE 1.1651; RMSE 2.2991\n",
      "Pi_val,mean,min,max tensor(0.2964, device='cuda:0') tensor(6.3198e-11, device='cuda:0') tensor(0.8285, device='cuda:0')\n",
      "1.7496046 6.319808e-11\n",
      "Epoch: 33\n",
      "Training loss: 158059.5589472158\n",
      "Epoch 33: trainNLL 158059.55895; valNLL 11098411.00000; MAE 1.1662; RMSE 2.2922\n",
      "Pi_val,mean,min,max tensor(0.2968, device='cuda:0') tensor(6.8260e-11, device='cuda:0') tensor(0.8247, device='cuda:0')\n",
      "1.7067257 6.825976e-11\n",
      "Epoch: 34\n",
      "Training loss: 157828.38712659513\n",
      "Epoch 34: trainNLL 157828.38713; valNLL 11078164.00000; MAE 1.1525; RMSE 2.2716\n",
      "Pi_val,mean,min,max tensor(0.2972, device='cuda:0') tensor(7.3004e-11, device='cuda:0') tensor(0.8383, device='cuda:0')\n",
      "1.7394854 7.300358e-11\n",
      "Epoch: 35\n",
      "Training loss: 157582.16338275812\n",
      "Epoch 35: trainNLL 157582.16338; valNLL 11063952.00000; MAE 1.1531; RMSE 2.2698\n",
      "Pi_val,mean,min,max tensor(0.2996, device='cuda:0') tensor(7.7781e-11, device='cuda:0') tensor(0.8492, device='cuda:0')\n",
      "1.7400342 7.778116e-11\n",
      "Epoch: 36\n",
      "Training loss: 157357.57058439674\n",
      "Epoch 36: trainNLL 157357.57058; valNLL 11051646.00000; MAE 1.1512; RMSE 2.2732\n",
      "Pi_val,mean,min,max tensor(0.2984, device='cuda:0') tensor(7.2685e-11, device='cuda:0') tensor(0.8488, device='cuda:0')\n",
      "1.7217747 7.26854e-11\n",
      "Epoch: 37\n",
      "Training loss: 157131.81021606727\n",
      "Epoch 37: trainNLL 157131.81022; valNLL 11035340.00000; MAE 1.1434; RMSE 2.2591\n",
      "Pi_val,mean,min,max tensor(0.2944, device='cuda:0') tensor(6.8288e-11, device='cuda:0') tensor(0.8367, device='cuda:0')\n",
      "1.7485731 6.828809e-11\n",
      "Epoch: 38\n",
      "Training loss: 156901.0828560035\n",
      "Epoch 38: trainNLL 156901.08286; valNLL 11020434.00000; MAE 1.1411; RMSE 2.2414\n",
      "Pi_val,mean,min,max tensor(0.2977, device='cuda:0') tensor(7.3234e-11, device='cuda:0') tensor(0.8568, device='cuda:0')\n",
      "1.7771791 7.3233704e-11\n",
      "Epoch: 39\n",
      "Training loss: 156708.69875652553\n",
      "Epoch 39: trainNLL 156708.69876; valNLL 11012160.00000; MAE 1.1469; RMSE 2.2638\n",
      "Pi_val,mean,min,max tensor(0.2976, device='cuda:0') tensor(7.0028e-11, device='cuda:0') tensor(0.8443, device='cuda:0')\n",
      "1.7178925 7.002813e-11\n",
      "Epoch: 40\n",
      "Training loss: 156502.02807787122\n",
      "Epoch 40: trainNLL 156502.02808; valNLL 10992285.00000; MAE 1.1301; RMSE 2.2323\n",
      "Pi_val,mean,min,max tensor(0.3046, device='cuda:0') tensor(6.8819e-11, device='cuda:0') tensor(0.8588, device='cuda:0')\n",
      "1.6707389 6.881901e-11\n",
      "Epoch: 41\n",
      "Training loss: 156309.57192575405\n",
      "Epoch 41: trainNLL 156309.57193; valNLL 10987944.00000; MAE 1.1237; RMSE 2.2432\n",
      "Pi_val,mean,min,max tensor(0.2959, device='cuda:0') tensor(5.9577e-11, device='cuda:0') tensor(0.8478, device='cuda:0')\n",
      "1.7611873 5.95771e-11\n",
      "Epoch: 42\n",
      "Training loss: 156118.92927059165\n",
      "Epoch 42: trainNLL 156118.92927; valNLL 10969302.00000; MAE 1.1299; RMSE 2.2269\n",
      "Pi_val,mean,min,max tensor(0.3003, device='cuda:0') tensor(6.0022e-11, device='cuda:0') tensor(0.8500, device='cuda:0')\n",
      "1.6706531 6.0022265e-11\n",
      "Epoch: 43\n",
      "Training loss: 155927.12200913572\n",
      "Epoch 43: trainNLL 155927.12201; valNLL 10955104.00000; MAE 1.1141; RMSE 2.2155\n",
      "Pi_val,mean,min,max tensor(0.2996, device='cuda:0') tensor(5.3655e-11, device='cuda:0') tensor(0.8528, device='cuda:0')\n",
      "1.7219646 5.3654976e-11\n",
      "Epoch: 44\n",
      "Training loss: 155750.1144050899\n",
      "Epoch 44: trainNLL 155750.11441; valNLL 10944574.00000; MAE 1.1185; RMSE 2.2173\n",
      "Pi_val,mean,min,max tensor(0.3015, device='cuda:0') tensor(5.3325e-11, device='cuda:0') tensor(0.8550, device='cuda:0')\n",
      "1.7012438 5.3324928e-11\n",
      "Epoch: 45\n",
      "Training loss: 155573.9455662703\n",
      "Epoch 45: trainNLL 155573.94557; valNLL 10935171.00000; MAE 1.1140; RMSE 2.2157\n",
      "Pi_val,mean,min,max tensor(0.2966, device='cuda:0') tensor(4.3690e-11, device='cuda:0') tensor(0.8553, device='cuda:0')\n",
      "1.7632701 4.3689923e-11\n",
      "Epoch: 46\n",
      "Training loss: 155412.94561158642\n",
      "Epoch 46: trainNLL 155412.94561; valNLL 10926839.00000; MAE 1.1220; RMSE 2.2233\n",
      "Pi_val,mean,min,max tensor(0.2946, device='cuda:0') tensor(3.9260e-11, device='cuda:0') tensor(0.8456, device='cuda:0')\n",
      "1.780453 3.9259634e-11\n",
      "Epoch: 47\n",
      "Training loss: 155239.35129966648\n",
      "Epoch 47: trainNLL 155239.35130; valNLL 10915950.00000; MAE 1.1205; RMSE 2.2121\n",
      "Pi_val,mean,min,max tensor(0.2954, device='cuda:0') tensor(3.5277e-11, device='cuda:0') tensor(0.8485, device='cuda:0')\n",
      "1.7689474 3.5277004e-11\n",
      "Epoch: 48\n",
      "Training loss: 155089.0670950551\n",
      "Epoch 48: trainNLL 155089.06710; valNLL 10903839.00000; MAE 1.1139; RMSE 2.1996\n",
      "Pi_val,mean,min,max tensor(0.2934, device='cuda:0') tensor(3.1260e-11, device='cuda:0') tensor(0.8416, device='cuda:0')\n",
      "1.7895439 3.125953e-11\n",
      "Epoch: 49\n",
      "Training loss: 154933.2698212732\n",
      "Epoch 49: trainNLL 154933.26982; valNLL 10897189.00000; MAE 1.1164; RMSE 2.2014\n",
      "Pi_val,mean,min,max tensor(0.2998, device='cuda:0') tensor(2.7986e-11, device='cuda:0') tensor(0.8511, device='cuda:0')\n",
      "1.7194483 2.7986254e-11\n",
      "Epoch: 50\n",
      "Training loss: 154793.21174412704\n",
      "Epoch 50: trainNLL 154793.21174; valNLL 10885093.00000; MAE 1.1033; RMSE 2.1938\n",
      "Pi_val,mean,min,max tensor(0.2938, device='cuda:0') tensor(2.2607e-11, device='cuda:0') tensor(0.8414, device='cuda:0')\n",
      "1.7891825 2.2607135e-11\n",
      "Epoch: 51\n",
      "Training loss: 154644.2634588892\n",
      "Epoch 51: trainNLL 154644.26346; valNLL 10879612.00000; MAE 1.1109; RMSE 2.1902\n",
      "Pi_val,mean,min,max tensor(0.2970, device='cuda:0') tensor(2.1049e-11, device='cuda:0') tensor(0.8423, device='cuda:0')\n",
      "1.731287 2.1049105e-11\n",
      "Epoch: 52\n",
      "Training loss: 154514.51981220997\n",
      "Epoch 52: trainNLL 154514.51981; valNLL 10866538.00000; MAE 1.0997; RMSE 2.1806\n",
      "Pi_val,mean,min,max tensor(0.2963, device='cuda:0') tensor(1.6692e-11, device='cuda:0') tensor(0.8495, device='cuda:0')\n",
      "1.772835 1.669205e-11\n",
      "Epoch: 53\n",
      "Training loss: 154384.61680684454\n",
      "Epoch 53: trainNLL 154384.61681; valNLL 10861424.00000; MAE 1.1044; RMSE 2.1891\n",
      "Pi_val,mean,min,max tensor(0.2941, device='cuda:0') tensor(1.4475e-11, device='cuda:0') tensor(0.8387, device='cuda:0')\n",
      "1.7633449 1.447473e-11\n",
      "Epoch: 54\n",
      "Training loss: 154255.28657011312\n",
      "Epoch 54: trainNLL 154255.28657; valNLL 10851190.00000; MAE 1.1000; RMSE 2.1754\n",
      "Pi_val,mean,min,max tensor(0.2957, device='cuda:0') tensor(1.1760e-11, device='cuda:0') tensor(0.8435, device='cuda:0')\n",
      "1.7672217 1.1759551e-11\n",
      "Epoch: 55\n",
      "Training loss: 154132.006081424\n",
      "Epoch 55: trainNLL 154132.00608; valNLL 10844466.00000; MAE 1.0994; RMSE 2.1773\n",
      "Pi_val,mean,min,max tensor(0.2950, device='cuda:0') tensor(1.0076e-11, device='cuda:0') tensor(0.8331, device='cuda:0')\n",
      "1.7653841 1.0076012e-11\n",
      "Epoch: 56\n",
      "Training loss: 154010.0389899942\n",
      "Epoch 56: trainNLL 154010.03899; valNLL 10837014.00000; MAE 1.0981; RMSE 2.1769\n",
      "Pi_val,mean,min,max tensor(0.2956, device='cuda:0') tensor(8.6664e-12, device='cuda:0') tensor(0.8385, device='cuda:0')\n",
      "1.7542325 8.666352e-12\n",
      "Epoch: 57\n",
      "Training loss: 153898.48070439385\n",
      "Epoch 57: trainNLL 153898.48070; valNLL 10827199.00000; MAE 1.0910; RMSE 2.1587\n",
      "Pi_val,mean,min,max tensor(0.2970, device='cuda:0') tensor(7.3688e-12, device='cuda:0') tensor(0.8415, device='cuda:0')\n",
      "1.7683096 7.368839e-12\n",
      "Epoch: 58\n",
      "Training loss: 153767.95213710846\n",
      "Epoch 58: trainNLL 153767.95214; valNLL 10824710.00000; MAE 1.0941; RMSE 2.1671\n",
      "Pi_val,mean,min,max tensor(0.2946, device='cuda:0') tensor(5.8104e-12, device='cuda:0') tensor(0.8265, device='cuda:0')\n",
      "1.7621275 5.8104316e-12\n",
      "Epoch: 59\n",
      "Training loss: 153661.43062101217\n",
      "Epoch 59: trainNLL 153661.43062; valNLL 10813768.00000; MAE 1.0893; RMSE 2.1539\n",
      "Pi_val,mean,min,max tensor(0.2939, device='cuda:0') tensor(5.1016e-12, device='cuda:0') tensor(0.8304, device='cuda:0')\n",
      "1.7835481 5.101583e-12\n",
      "Epoch: 60\n",
      "Training loss: 153561.77624709977\n",
      "Epoch 60: trainNLL 153561.77625; valNLL 10810947.00000; MAE 1.0926; RMSE 2.1599\n",
      "Pi_val,mean,min,max tensor(0.2935, device='cuda:0') tensor(4.3160e-12, device='cuda:0') tensor(0.8267, device='cuda:0')\n",
      "1.8019966 4.3160254e-12\n",
      "Epoch: 61\n",
      "Training loss: 153456.5388087297\n",
      "Epoch 61: trainNLL 153456.53881; valNLL 10804467.00000; MAE 1.0929; RMSE 2.1563\n",
      "Pi_val,mean,min,max tensor(0.2970, device='cuda:0') tensor(3.6802e-12, device='cuda:0') tensor(0.8343, device='cuda:0')\n",
      "1.7563616 3.6801642e-12\n",
      "Epoch: 62\n",
      "Training loss: 153350.00444098026\n",
      "Epoch 62: trainNLL 153350.00444; valNLL 10795558.00000; MAE 1.0847; RMSE 2.1553\n",
      "Pi_val,mean,min,max tensor(0.2929, device='cuda:0') tensor(2.8280e-12, device='cuda:0') tensor(0.8206, device='cuda:0')\n",
      "1.7944014 2.8279935e-12\n",
      "Epoch: 63\n",
      "Training loss: 153251.8085212442\n",
      "Epoch 63: trainNLL 153251.80852; valNLL 10792966.00000; MAE 1.0904; RMSE 2.1556\n",
      "Pi_val,mean,min,max tensor(0.2939, device='cuda:0') tensor(2.5072e-12, device='cuda:0') tensor(0.8224, device='cuda:0')\n",
      "1.7863854 2.5072132e-12\n",
      "Epoch: 64\n",
      "Training loss: 153160.15431953306\n",
      "Epoch 64: trainNLL 153160.15432; valNLL 10787385.00000; MAE 1.0875; RMSE 2.1508\n",
      "Pi_val,mean,min,max tensor(0.2903, device='cuda:0') tensor(1.8196e-12, device='cuda:0') tensor(0.8116, device='cuda:0')\n",
      "1.8059694 1.8195528e-12\n",
      "Epoch: 65\n",
      "Training loss: 153063.93166328306\n",
      "Epoch 65: trainNLL 153063.93166; valNLL 10782776.00000; MAE 1.0866; RMSE 2.1371\n",
      "Pi_val,mean,min,max tensor(0.2975, device='cuda:0') tensor(1.4616e-12, device='cuda:0') tensor(0.8305, device='cuda:0')\n",
      "1.7630951 1.461599e-12\n",
      "Epoch: 66\n",
      "Training loss: 152979.40934962296\n",
      "Epoch 66: trainNLL 152979.40935; valNLL 10775531.00000; MAE 1.0813; RMSE 2.1493\n",
      "Pi_val,mean,min,max tensor(0.2992, device='cuda:0') tensor(1.2548e-12, device='cuda:0') tensor(0.8275, device='cuda:0')\n",
      "1.7426512 1.2548465e-12\n",
      "Epoch: 67\n",
      "Training loss: 152888.7812137471\n",
      "Epoch 67: trainNLL 152888.78121; valNLL 10771295.00000; MAE 1.0791; RMSE 2.1507\n",
      "Pi_val,mean,min,max tensor(0.2964, device='cuda:0') tensor(1.0494e-12, device='cuda:0') tensor(0.8272, device='cuda:0')\n",
      "1.8046347 1.049399e-12\n",
      "Epoch: 68\n",
      "Training loss: 152803.63764319895\n",
      "Epoch 68: trainNLL 152803.63764; valNLL 10768065.00000; MAE 1.0857; RMSE 2.1506\n",
      "Pi_val,mean,min,max tensor(0.2989, device='cuda:0') tensor(8.5891e-13, device='cuda:0') tensor(0.8158, device='cuda:0')\n",
      "1.7168897 8.589078e-13\n",
      "Epoch: 69\n",
      "Training loss: 152720.98131162993\n",
      "Epoch 69: trainNLL 152720.98131; valNLL 10755197.00000; MAE 1.0681; RMSE 2.1207\n",
      "Pi_val,mean,min,max tensor(0.2931, device='cuda:0') tensor(6.7275e-13, device='cuda:0') tensor(0.8123, device='cuda:0')\n",
      "1.8131027 6.7275173e-13\n",
      "Epoch: 70\n",
      "Training loss: 152629.02374564964\n",
      "Epoch 70: trainNLL 152629.02375; valNLL 10756715.00000; MAE 1.0829; RMSE 2.1346\n",
      "Pi_val,mean,min,max tensor(0.2942, device='cuda:0') tensor(5.4981e-13, device='cuda:0') tensor(0.8152, device='cuda:0')\n",
      "1.7882297 5.498093e-13\n",
      "Epoch: 71\n",
      "Training loss: 152558.57497099767\n",
      "Epoch 71: trainNLL 152558.57497; valNLL 10750393.00000; MAE 1.0800; RMSE 2.1409\n",
      "Pi_val,mean,min,max tensor(0.2983, device='cuda:0') tensor(4.9676e-13, device='cuda:0') tensor(0.8113, device='cuda:0')\n",
      "1.7358547 4.9676344e-13\n",
      "Epoch: 72\n",
      "Training loss: 152468.09207330336\n",
      "Epoch 72: trainNLL 152468.09207; valNLL 10740526.00000; MAE 1.0680; RMSE 2.1232\n",
      "Pi_val,mean,min,max tensor(0.2962, device='cuda:0') tensor(3.9958e-13, device='cuda:0') tensor(0.8036, device='cuda:0')\n",
      "1.7455176 3.9957572e-13\n",
      "Epoch: 73\n",
      "Training loss: 152374.57520664154\n",
      "Epoch 73: trainNLL 152374.57521; valNLL 10736924.00000; MAE 1.0694; RMSE 2.1247\n",
      "Pi_val,mean,min,max tensor(0.2957, device='cuda:0') tensor(3.1908e-13, device='cuda:0') tensor(0.8047, device='cuda:0')\n",
      "1.8004664 3.190757e-13\n",
      "Epoch: 74\n",
      "Training loss: 152296.882449971\n",
      "Epoch 74: trainNLL 152296.88245; valNLL 10735487.00000; MAE 1.0763; RMSE 2.1283\n",
      "Pi_val,mean,min,max tensor(0.2951, device='cuda:0') tensor(2.5492e-13, device='cuda:0') tensor(0.8114, device='cuda:0')\n",
      "1.8154998 2.5491848e-13\n",
      "Epoch: 75\n",
      "Training loss: 152227.10748984918\n",
      "Epoch 75: trainNLL 152227.10749; valNLL 10735225.00000; MAE 1.0798; RMSE 2.1394\n",
      "Pi_val,mean,min,max tensor(0.2946, device='cuda:0') tensor(2.1593e-13, device='cuda:0') tensor(0.7921, device='cuda:0')\n",
      "1.7672782 2.159344e-13\n",
      "Epoch: 76\n",
      "Training loss: 152156.2033787703\n",
      "Epoch 76: trainNLL 152156.20338; valNLL 10721760.00000; MAE 1.0654; RMSE 2.1023\n",
      "Pi_val,mean,min,max tensor(0.2977, device='cuda:0') tensor(1.7211e-13, device='cuda:0') tensor(0.8038, device='cuda:0')\n",
      "1.773122 1.7210834e-13\n",
      "Epoch: 77\n",
      "Training loss: 152087.39897223026\n",
      "Epoch 77: trainNLL 152087.39897; valNLL 10722568.00000; MAE 1.0695; RMSE 2.1208\n",
      "Pi_val,mean,min,max tensor(0.2967, device='cuda:0') tensor(1.2869e-13, device='cuda:0') tensor(0.8016, device='cuda:0')\n",
      "1.798229 1.2868752e-13\n",
      "Epoch: 78\n",
      "Training loss: 152030.62713892112\n",
      "Epoch 78: trainNLL 152030.62714; valNLL 10720644.00000; MAE 1.0742; RMSE 2.1323\n",
      "Pi_val,mean,min,max tensor(0.2920, device='cuda:0') tensor(1.0159e-13, device='cuda:0') tensor(0.7832, device='cuda:0')\n",
      "1.810736 1.01593206e-13\n",
      "Epoch: 79\n",
      "Training loss: 151964.418331279\n",
      "Epoch 79: trainNLL 151964.41833; valNLL 10714878.00000; MAE 1.0720; RMSE 2.1120\n",
      "Pi_val,mean,min,max tensor(0.2898, device='cuda:0') tensor(7.7335e-14, device='cuda:0') tensor(0.7816, device='cuda:0')\n",
      "1.8521684 7.733467e-14\n",
      "Epoch: 80\n",
      "Training loss: 151893.45245432135\n",
      "Epoch 80: trainNLL 151893.45245; valNLL 10719457.00000; MAE 1.0803; RMSE 2.1241\n",
      "Pi_val,mean,min,max tensor(0.2927, device='cuda:0') tensor(6.5608e-14, device='cuda:0') tensor(0.7867, device='cuda:0')\n",
      "1.8429763 6.5608373e-14\n",
      "Epoch: 81\n",
      "Training loss: 151847.05716176043\n",
      "Epoch 81: trainNLL 151847.05716; valNLL 10713339.00000; MAE 1.0785; RMSE 2.1294\n",
      "Pi_val,mean,min,max tensor(0.2976, device='cuda:0') tensor(5.3204e-14, device='cuda:0') tensor(0.7885, device='cuda:0')\n",
      "1.777527 5.3204372e-14\n",
      "Epoch: 82\n",
      "Training loss: 151776.584124855\n",
      "Epoch 82: trainNLL 151776.58412; valNLL 10703206.00000; MAE 1.0662; RMSE 2.1166\n",
      "Pi_val,mean,min,max tensor(0.2942, device='cuda:0') tensor(4.2337e-14, device='cuda:0') tensor(0.7708, device='cuda:0')\n",
      "1.7834166 4.2336824e-14\n",
      "Epoch: 83\n",
      "Training loss: 151731.21083780454\n",
      "Epoch 83: trainNLL 151731.21084; valNLL 10696682.00000; MAE 1.0620; RMSE 2.0930\n",
      "Pi_val,mean,min,max tensor(0.2954, device='cuda:0') tensor(3.5383e-14, device='cuda:0') tensor(0.7819, device='cuda:0')\n",
      "1.8003343 3.5383324e-14\n",
      "Epoch: 84\n",
      "Training loss: 151671.64050717806\n",
      "Epoch 84: trainNLL 151671.64051; valNLL 10698147.00000; MAE 1.0682; RMSE 2.1145\n",
      "Pi_val,mean,min,max tensor(0.2981, device='cuda:0') tensor(3.0114e-14, device='cuda:0') tensor(0.7837, device='cuda:0')\n",
      "1.782914 3.0113953e-14\n",
      "Epoch: 85\n",
      "Training loss: 151612.71135440835\n",
      "Epoch 85: trainNLL 151612.71135; valNLL 10696701.00000; MAE 1.0671; RMSE 2.1236\n",
      "Pi_val,mean,min,max tensor(0.2959, device='cuda:0') tensor(2.1168e-14, device='cuda:0') tensor(0.7716, device='cuda:0')\n",
      "1.7696972 2.1168292e-14\n",
      "Epoch: 86\n",
      "Training loss: 151554.41872099767\n",
      "Epoch 86: trainNLL 151554.41872; valNLL 10688822.00000; MAE 1.0613; RMSE 2.1045\n",
      "Pi_val,mean,min,max tensor(0.2953, device='cuda:0') tensor(1.7890e-14, device='cuda:0') tensor(0.7674, device='cuda:0')\n",
      "1.7875929 1.7889522e-14\n",
      "Epoch: 87\n",
      "Training loss: 151506.5188786978\n",
      "Epoch 87: trainNLL 151506.51888; valNLL 10689288.00000; MAE 1.0647; RMSE 2.1102\n",
      "Pi_val,mean,min,max tensor(0.2946, device='cuda:0') tensor(1.4422e-14, device='cuda:0') tensor(0.7740, device='cuda:0')\n",
      "1.8080959 1.4422423e-14\n",
      "Epoch: 88\n",
      "Training loss: 151458.25139573665\n",
      "Epoch 88: trainNLL 151458.25140; valNLL 10685457.00000; MAE 1.0658; RMSE 2.1079\n",
      "Pi_val,mean,min,max tensor(0.2934, device='cuda:0') tensor(1.3014e-14, device='cuda:0') tensor(0.7613, device='cuda:0')\n",
      "1.7761707 1.3014331e-14\n",
      "Epoch: 89\n",
      "Training loss: 151413.08170497388\n",
      "Epoch 89: trainNLL 151413.08170; valNLL 10678834.00000; MAE 1.0577; RMSE 2.0873\n",
      "Pi_val,mean,min,max tensor(0.2956, device='cuda:0') tensor(1.1223e-14, device='cuda:0') tensor(0.7585, device='cuda:0')\n",
      "1.7678611 1.1222855e-14\n",
      "Epoch: 90\n",
      "Training loss: 151370.11522078016\n",
      "Epoch 90: trainNLL 151370.11522; valNLL 10675165.00000; MAE 1.0556; RMSE 2.0856\n",
      "Pi_val,mean,min,max tensor(0.2998, device='cuda:0') tensor(1.0242e-14, device='cuda:0') tensor(0.7570, device='cuda:0')\n",
      "1.6999272 1.0242221e-14\n",
      "Epoch: 91\n",
      "Training loss: 151315.713837732\n",
      "Epoch 91: trainNLL 151315.71384; valNLL 10672624.00000; MAE 1.0462; RMSE 2.0776\n",
      "Pi_val,mean,min,max tensor(0.2931, device='cuda:0') tensor(8.3721e-15, device='cuda:0') tensor(0.7518, device='cuda:0')\n",
      "1.7868345 8.372071e-15\n",
      "Epoch: 92\n",
      "Training loss: 151270.01738326566\n",
      "Epoch 92: trainNLL 151270.01738; valNLL 10671116.00000; MAE 1.0574; RMSE 2.0850\n",
      "Pi_val,mean,min,max tensor(0.2912, device='cuda:0') tensor(7.3287e-15, device='cuda:0') tensor(0.7402, device='cuda:0')\n",
      "1.7995393 7.328666e-15\n",
      "Epoch: 93\n",
      "Training loss: 151221.937137471\n",
      "Epoch 93: trainNLL 151221.93714; valNLL 10670736.00000; MAE 1.0593; RMSE 2.0855\n",
      "Pi_val,mean,min,max tensor(0.2935, device='cuda:0') tensor(6.2245e-15, device='cuda:0') tensor(0.7540, device='cuda:0')\n",
      "1.8475463 6.2244953e-15\n",
      "Epoch: 94\n",
      "Training loss: 151180.23964979697\n",
      "Epoch 94: trainNLL 151180.23965; valNLL 10675945.00000; MAE 1.0707; RMSE 2.1130\n",
      "Pi_val,mean,min,max tensor(0.2896, device='cuda:0') tensor(5.5823e-15, device='cuda:0') tensor(0.7385, device='cuda:0')\n",
      "1.8322892 5.582327e-15\n",
      "Epoch: 95\n",
      "Training loss: 151141.38930176914\n",
      "Epoch 95: trainNLL 151141.38930; valNLL 10669445.00000; MAE 1.0628; RMSE 2.0842\n",
      "Pi_val,mean,min,max tensor(0.2977, device='cuda:0') tensor(5.4736e-15, device='cuda:0') tensor(0.7597, device='cuda:0')\n",
      "1.8011659 5.47364e-15\n",
      "Epoch: 96\n",
      "Training loss: 151095.26588783352\n",
      "Epoch 96: trainNLL 151095.26589; valNLL 10665166.00000; MAE 1.0603; RMSE 2.0999\n",
      "Pi_val,mean,min,max tensor(0.2956, device='cuda:0') tensor(4.7159e-15, device='cuda:0') tensor(0.7516, device='cuda:0')\n",
      "1.7949561 4.715904e-15\n",
      "Epoch: 97\n",
      "Training loss: 151056.00750435036\n",
      "Epoch 97: trainNLL 151056.00750; valNLL 10661944.00000; MAE 1.0597; RMSE 2.0981\n",
      "Pi_val,mean,min,max tensor(0.2978, device='cuda:0') tensor(4.5404e-15, device='cuda:0') tensor(0.7591, device='cuda:0')\n",
      "1.7874829 4.5403588e-15\n",
      "Epoch: 98\n",
      "Training loss: 151020.07126413862\n",
      "Epoch 98: trainNLL 151020.07126; valNLL 10660370.00000; MAE 1.0566; RMSE 2.0949\n",
      "Pi_val,mean,min,max tensor(0.2940, device='cuda:0') tensor(3.9626e-15, device='cuda:0') tensor(0.7463, device='cuda:0')\n",
      "1.793894 3.962614e-15\n",
      "Epoch: 99\n",
      "Training loss: 150985.60455336428\n",
      "Epoch 99: trainNLL 150985.60455; valNLL 10655575.00000; MAE 1.0563; RMSE 2.0854\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import generate_dataset, get_normalized_adj, get_Laplace, calculate_random_walk_matrix,nb_zeroinflated_nll_loss,nb_zeroinflated_draw\n",
    "from model import *\n",
    "import random,os,copy\n",
    "import math\n",
    "import tqdm\n",
    "from scipy.stats import nbinom\n",
    "import pickle as pk\n",
    "import os, warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "# Parameters\n",
    "torch.manual_seed(0)\n",
    "device = torch.device('cuda') \n",
    "A = np.load('ny_data_full_60min/adj_rand0.npy') # change the loading folder\n",
    "X = np.load('ny_data_full_60min/cta_samp_rand0.npy')\n",
    "\n",
    "num_timesteps_output = 4 \n",
    "num_timesteps_input = num_timesteps_output\n",
    "\n",
    "space_dim = X.shape[1]\n",
    "batch_size = 4\n",
    "hidden_dim_s = 70\n",
    "hidden_dim_t = 7\n",
    "rank_s = 20\n",
    "rank_t = 4\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "# Initial networks\n",
    "TCN1 = B_TCN(space_dim, hidden_dim_t, kernel_size=3).to(device=device)\n",
    "TCN2 = B_TCN(hidden_dim_t, rank_t, kernel_size = 3, activation = 'linear').to(device=device)\n",
    "TCN3 = B_TCN(rank_t, hidden_dim_t, kernel_size= 3).to(device=device)\n",
    "TNB = NBNorm_ZeroInflated(hidden_dim_t,space_dim).to(device=device)\n",
    "SCN1 = D_GCN(num_timesteps_input, hidden_dim_s, 3).to(device=device)\n",
    "SCN2 = D_GCN(hidden_dim_s, rank_s, 2, activation = 'linear').to(device=device)\n",
    "SCN3 = D_GCN(rank_s, hidden_dim_s, 2).to(device=device)\n",
    "SNB = NBNorm_ZeroInflated(hidden_dim_s,num_timesteps_output).to(device=device)\n",
    "STmodel = ST_NB_ZeroInflated(SCN1, SCN2, SCN3, TCN1, TCN2, TCN3, SNB,TNB).to(device=device)\n",
    "\n",
    "# Load dataset\n",
    "\n",
    "X = X.T\n",
    "X = X.astype(np.float32)\n",
    "X = X.reshape((X.shape[0],1,X.shape[1]))\n",
    "\n",
    "split_line1 = int(X.shape[2] * 0.6)\n",
    "split_line2 = int(X.shape[2] * 0.7)\n",
    "print(X.shape,A.shape)\n",
    "\n",
    "# normalization\n",
    "max_value = np.max(X[:, :, :split_line1])\n",
    "\n",
    "train_original_data = X[:, :, :split_line1]\n",
    "val_original_data = X[:, :, split_line1:split_line2]\n",
    "test_original_data = X[:, :, split_line2:]\n",
    "training_input, training_target = generate_dataset(train_original_data,\n",
    "                                                    num_timesteps_input=num_timesteps_input,\n",
    "                                                    num_timesteps_output=num_timesteps_output)\n",
    "val_input, val_target = generate_dataset(val_original_data,\n",
    "                                            num_timesteps_input=num_timesteps_input,\n",
    "                                            num_timesteps_output=num_timesteps_output)\n",
    "test_input, test_target = generate_dataset(test_original_data,\n",
    "                                            num_timesteps_input=num_timesteps_input,\n",
    "                                            num_timesteps_output=num_timesteps_output)\n",
    "print('input shape: ',training_input.shape,val_input.shape,test_input.shape)\n",
    "\n",
    "\n",
    "A_wave = get_normalized_adj(A)\n",
    "A_q = torch.from_numpy((calculate_random_walk_matrix(A_wave).T).astype('float32'))\n",
    "A_h = torch.from_numpy((calculate_random_walk_matrix(A_wave.T).T).astype('float32'))\n",
    "A_q = A_q.to(device=device)\n",
    "A_h = A_h.to(device=device)\n",
    "# Define the training process\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(STmodel.parameters(), lr=1e-5)\n",
    "training_nll   = []\n",
    "validation_nll = []\n",
    "validation_mae = []\n",
    "validation_rmse = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## Step 1, training\n",
    "    \"\"\"\n",
    "    # Begin training, similar training procedure from STGCN\n",
    "    Trains one epoch with the given data.\n",
    "    :param training_input: Training inputs of shape (num_samples, num_nodes,\n",
    "    num_timesteps_train, num_features).\n",
    "    :param training_target: Training targets of shape (num_samples, num_nodes,\n",
    "    num_timesteps_predict).\n",
    "    :param batch_size: Batch size to use during training.\n",
    "    \"\"\"\n",
    "    permutation = torch.randperm(training_input.shape[0])\n",
    "    epoch_training_losses = []\n",
    "    for i in range(0, training_input.shape[0], batch_size):\n",
    "        STmodel.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        indices = permutation[i:i + batch_size]\n",
    "        X_batch, y_batch = training_input[indices], training_target[indices]\n",
    "        X_batch = X_batch.to(device=device)\n",
    "        y_batch = y_batch.to(device=device)\n",
    "\n",
    "        n_train,p_train,pi_train = STmodel(X_batch,A_q,A_h)\n",
    "        loss = nb_zeroinflated_nll_loss(y_batch,n_train,p_train,pi_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_training_losses.append(loss.detach().cpu().numpy())\n",
    "    training_nll.append(sum(epoch_training_losses)/len(epoch_training_losses))\n",
    "    ## Step 2, validation\n",
    "    with torch.no_grad():\n",
    "        STmodel.eval()\n",
    "        val_input = val_input.to(device=device)\n",
    "        val_target = val_target.to(device=device)\n",
    "\n",
    "        n_val,p_val,pi_val = STmodel(val_input,A_q,A_h)\n",
    "        print('Pi_val,mean,min,max',torch.mean(pi_val),torch.min(pi_val),torch.max(pi_val))\n",
    "        val_loss    = nb_zeroinflated_nll_loss(val_target,n_val,p_val,pi_val).to(device=\"cpu\")\n",
    "        validation_nll.append(np.asscalar(val_loss.detach().numpy()))\n",
    "\n",
    "        # Calculate the expectation value        \n",
    "        val_pred = (1-pi_val.detach().cpu().numpy())*(n_val.detach().cpu().numpy()/p_val.detach().cpu().numpy()-n_val.detach().cpu().numpy()) # pipred\n",
    "        print(val_pred.mean(),pi_val.detach().cpu().numpy().min())\n",
    "        mae = np.mean(np.abs(val_pred - val_target.detach().cpu().numpy()))\n",
    "        rmse = np.sqrt(((val_pred - val_target.detach().cpu().numpy()) ** 2).mean())\n",
    "        validation_mae.append(mae)\n",
    "        validation_rmse.append(rmse)\n",
    "\n",
    "        n_val,p_val,pi_val = None,None,None\n",
    "        val_input = val_input.to(device=\"cpu\")\n",
    "        val_target = val_target.to(device=\"cpu\")\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    print(\"Training loss: {}\".format(training_nll[-1]))\n",
    "    print('Epoch %d: trainNLL %.5f; valNLL %.5f; MAE %.4f; RMSE %.4f'%(epoch,\n",
    "    training_nll[-1],validation_nll[-1],validation_mae[-1], validation_rmse[-1]))\n",
    "    if np.asscalar(training_nll[-1]) == min(training_nll):\n",
    "        best_model = copy.deepcopy(STmodel.state_dict())\n",
    "    checkpoint_path = \"checkpoints/\"\n",
    "    if not os.path.exists(checkpoint_path):\n",
    "        os.makedirs(checkpoint_path)\n",
    "    with open(\"checkpoints/losses.pk\", \"wb\") as fd:\n",
    "        pk.dump((training_nll, validation_nll, validation_mae), fd)\n",
    "    if np.isnan(training_nll[-1]):\n",
    "        break\n",
    "STmodel.load_state_dict(best_model)\n",
    "torch.save(STmodel,'pth/STZINB_ny_full_5min.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TalkNet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
